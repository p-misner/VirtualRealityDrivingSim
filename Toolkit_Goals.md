# Toolkit Goals
## Purpose

## Development Goals
### Must Haves
1. Create a series of scripts that allow the user to drive both autonomously and manually
2. Give user tools to reduce sim-sicknesses
3. Allow user to place pedestrians, bicyclists and other common moving roadside objects onto the road
  * User will be able to customize pedestrian model used, stop and start destination and speed or time to reach
4. Allow user to set up auditory distraction tasks that either play an audio file on a trigger or every x seconds
5. Allow user to indicate what data they would like to get out of the Oculus (head movement, response time, audio record distraction task responses)
  * Scripts will also output data into a csv file for later analysis
  * Nice to have: Prewritten python code to visualize common data types aka head tracking data
6. In world-buttons for the user to press
### Additional Add-Ons
1. A cellphone with a changeable for distracted driving studies
2. Visual distraction tasks
  * More thought on what this might look like beyond a video playing or AR cues


